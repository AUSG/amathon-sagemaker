{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 04\n",
    "\n",
    "## 1. MNIST\n",
    "- 손글씨 숫자 이미지 집합\n",
    "- 기계학습 분야에서 널리 사용되는 오픈소스 데이터셋\n",
    "- Training Dataset : 60,000\n",
    "- Test Dataset : 10,000\n",
    "- 각 이미지는 28x28 픽셀\n",
    "- 각 픽셀 : 0~255 사이의 값\n",
    "- 각 이미지 별로 정답을 나타내는 레이블이 존재한다.\n",
    "\n",
    "## 2. 구현하기\n",
    "- ipynb 파일을 import 하기 위해서는 import_ipynb 패키지가 필요하다.\n",
    "- pip install import_ipynb\n",
    "- 사전에 구현해놓은 mnist.ipynb 파일을 사용한다.\n",
    "- load_mnist() 함수를 호츨하면 인터넷에서 Dataset을 다운로드한다.\n",
    "- 두번째 호출부터는 로컬에 저장된 pickle 파일을 읽어온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Data 모양 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from mnist import load_mnist\n",
    "\n",
    "# Dataset load\n",
    "# 전처리 옵션들\n",
    "# normalize : 이미지의 픽셀 값은 0.0~1.0 사이의 값으로 정규화 할지 여부\n",
    "# flatten : 입력 이미지를 1차원 배열로 만들지 여부 (True : 784, False : 1x28x28)\n",
    "# one_hot_label : one-hot encoding으로 저장할지 여부. True : [0,0,1,0,0,0,0,0,0], False : 2\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten = True, normalize=False)\n",
    "\n",
    "print(x_train.shape) # (60000, 784)\n",
    "print(t_train.shape) # (60000, )\n",
    "print(x_test.shape)  # (10000, 784)\n",
    "print(t_test.shape)  # (10000, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 이미지 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(784,)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 이미지 확인해보기\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()\n",
    "    \n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten = True, normalize=False)\n",
    "\n",
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label) # 5\n",
    "\n",
    "print(img.shape)          #(784,)\n",
    "img = img.reshape(28, 28) # 원래 이미지 모양으로 변형\n",
    "print(img.shape)          # (28, 28)\n",
    "\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 추론해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Chapter_03 as af\n",
    "import pickle\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(flatten = True, normalize=False, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\",'rb') as f: # 사전에 세팅해 놓은 가중치 값\n",
    "        network = pickle.load(f)\n",
    "        \n",
    "    return network\n",
    "\n",
    "def predict(network, x):\n",
    "    # 은닉층 2층, 출력층 1층인 신경망\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = af.relu(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = af.relu(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y= af.softmax(a3)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8286\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p = np.argmax(y) # 가장 큰 원소의 인덱스 리턴\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt)/len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch 처리\n",
    "- Batch : 하나로 묶은 입력 데이터\n",
    "- 데이터 하나당 배열 하나가 아니라 배열 하나에 데이터 여러개를 담고있다.\n",
    "- 수치계산 라이브러리 대부분이 큰 배열을 효율적으로 처리할 수 있도록 최적화 되어있다.\n",
    "- 데이터 전송의 병목현상을 줄여준다.\n",
    "- 작은 것 여러번 보다 큰 것 한번 처리하는게 속도가 빠르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.1003\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100 # 배치 크기\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1) # 1번째 차원을 축으로 각 원소들의 최대값을 찾음. 여기서는 각 행이 1차원.\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt)/len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
